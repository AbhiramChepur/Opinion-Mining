{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Training Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Training Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of rows and Columns in Training Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup  \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to preprocess the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_words( raw_review ):\n",
    "\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    return( \" \".join( meaningful_words ))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling the function to preprocess the data on our training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_reviews = train[\"reviewText\"].size\n",
    "print (\"Cleaning the training set reviews...\\n\")\n",
    "clean_train_reviews = []\n",
    "for i in range( 0, num_reviews ):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print (\"Review %d of %d\\n\" % ( i+1, num_reviews ))                                                                    \n",
    "    clean_train_reviews.append( review_to_words( train[\"reviewText\"][i] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Pre Processed Reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_train_reviews[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Bag of Words to train our dataset on the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Creating bag of words...\\n\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the CountVectorizer object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. \n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_matrix = train_data_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the features set along with the number of occurences of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vocab = vectorizer.get_feature_names()\n",
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(train_data_features, axis=0)\n",
    "\n",
    "# print the vocabulary word and the number of times it \n",
    "# appears in the training set\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print (tag,count)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our data using the features with Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Training the random forest...\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "\n",
    "forest = forest.fit( train_data_features, train[\"rating\"] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying our  Random Forest model on test set to predict the polarity of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "\n",
    "print (test.shape)\n",
    "\n",
    "# Create an empty list and append the clean reviews one by one\n",
    "num_reviews = len(test[\"reviewText\"])\n",
    "clean_test_reviews = [] \n",
    "\n",
    "print (\"Cleaning the test set reviews...\\n\")\n",
    "for i in range(0,num_reviews):\n",
    "    if( (i+1) % 1000 == 0 ):\n",
    "        print (\"Review %d of %d\\n\" % (i+1, num_reviews))\n",
    "    clean_review = review_to_words( test[\"reviewText\"][i] )\n",
    "    clean_test_reviews.append( clean_review )\n",
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features = vectorizer.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "# Use the random forest to make label predictions\n",
    "result = forest.predict(test_data_features)\n",
    "\n",
    "# Copy the results to a pandas dataframe \n",
    "output = pd.DataFrame( data={\"reviewText\":test[\"reviewText\"], \"predicted\":result , \"originalRating\" :test[\"actual\"] } )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data set along with the predicted Polarity and original rating for Random Forest      classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of our Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print (\"Accuracy Rate, which is calculated by accuracy_score() is: %f\" % accuracy_score(output.originalRating, output.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(output.originalRating, output.predicted, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our data using the features with Multinomial Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit( train_data_features, train[\"rating\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying our  Naive Bayes model on test set to predict the polarity of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_reviews = len(test[\"reviewText\"])\n",
    "clean_test_reviews = [] \n",
    "\n",
    "print (\"Cleaning the test set reviews...\\n\")\n",
    "for i in range(0,num_reviews):\n",
    "    if( (i+1) % 1000 == 0 ):\n",
    "        print (\"Review %d of %d\\n\" % (i+1, num_reviews))\n",
    "    clean_review = review_to_words( test[\"reviewText\"][i] )\n",
    "    clean_test_reviews.append( clean_review )\n",
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features = vectorizer.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "# Use the Naive Bayes to make label predictions\n",
    "result2 = nb.predict(test_data_features)\n",
    "\n",
    "# Copy the results to a pandas dataframe with an \"id\" column and\n",
    "# a \"predicted\" column\n",
    "output2 = pd.DataFrame( data={\"reviewText\":test[\"reviewText\"], \"predicted\":result2 , \"originalRating\" :test[\"actual\"]} )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data set along with the predicted Polarity and original rating for Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output2.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of our Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Accuracy Rate for Naive Bayes Classifier, which is calculated by accuracy_score() is: %f\" % accuracy_score(output2.originalRating, output2.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(output2.originalRating, output2.predicted,average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our data using the features with Support Vector Machines Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf1 = svm.SVC()\n",
    "clf1.fit(train_data_features, train[\"rating\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying our  SVM model on test set to predict the polarity of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_reviews = len(test[\"reviewText\"])\n",
    "clean_test_reviews = [] \n",
    "print (\"Cleaning the test set reviews...\\n\")\n",
    "for i in range(0,num_reviews):\n",
    "    if( (i+1) % 1000 == 0 ):\n",
    "        print (\"Review %d of %d\\n\" % (i+1, num_reviews))\n",
    "    clean_review = review_to_words( test[\"reviewText\"][i] )\n",
    "    clean_test_reviews.append( clean_review )\n",
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features = vectorizer.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "# Use the SVM to make sentiment label predictions\n",
    "result10 = clf1.predict(test_data_features)\n",
    "\n",
    "# Copy the results to a pandas dataframe \n",
    "output3 = pd.DataFrame( data={\"reviewText\":test[\"reviewText\"], \"predicted\":result10, \"originalRating\" :test[\"actual\"]} )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data set along with the predicted Polarity and original rating for SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output3.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Accuracy Rate for SVM classifier, which is calculated by accuracy_score() is: %f\" % accuracy_score(output3.originalRating, output3.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(output3.originalRating, output3.predicted,average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our Data using features with logistic regression classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Training the logistic regression...\")\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "\n",
    "logreg1 = linear_model.LogisticRegression(C=1e5) \n",
    "\n",
    "\n",
    "\n",
    "logreg1 = logreg1.fit( train_data_features, train[\"rating\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying our logistic regression model to predict the polarity of the reviews in Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_reviews = len(test[\"reviewText\"])\n",
    "clean_test_reviews = [] \n",
    "print (\"Cleaning the test set reviews...\\n\")\n",
    "for i in range(0,num_reviews):\n",
    "    if( (i+1) % 1000 == 0 ):\n",
    "        print (\"Review %d of %d\\n\" % (i+1, num_reviews))\n",
    "    clean_review = review_to_words( test[\"reviewText\"][i] )\n",
    "    clean_test_reviews.append( clean_review )\n",
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features = vectorizer.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "# Use the SVM to make sentiment label predictions\n",
    "result9 = logreg1.predict(test_data_features)\n",
    "\n",
    "# Copy the results to a pandas dataframe with an \"id\" column and\n",
    "# a \"predicted\" column\n",
    "output9 = pd.DataFrame( data={\"reviewText\":test[\"reviewText\"], \"predicted\":result9, \"originalRating\" :test[\"actual\"]} )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of the Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Accuracy Rate for logistic classifier, which is calculated by accuracy_score() is: %f\" % accuracy_score(output9.originalRating, output9.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F - Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(output9.originalRating, output9.predicted,average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing train data to classify Data to three labels ie, Postive(1) ,Negative(-1) or Neutral(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train2 = pd.read_csv(\"train3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train2.reviewText.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the new Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup  \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_reviews2 = train2[\"reviewText\"].size\n",
    "print (\"Cleaning the training set reviews...\\n\")\n",
    "clean_train_reviews2 = []\n",
    "for i in range( 0, num_reviews2 ):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print (\"Review %d of %d\\n\" % ( i+1, num_reviews2 ))                                                                    \n",
    "    clean_train_reviews2.append( review_to_words( train2[\"reviewText\"][i] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building bag of words to the new data set and getting the features to train data on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Creating bag of words...\\n\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer2 = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. \n",
    "train_data_features2 = vectorizer2.fit_transform(clean_train_reviews2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_features2 = train_data_features2.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Training our data using the features with Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Training the random forest...\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest2 = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest2 = forest2.fit( train_data_features2, train2[\"rating1\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying our  Random Forest model on test set to predict the polarity of the review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test2 = pd.read_csv(\"test3.csv\")\n",
    "\n",
    "\n",
    "print (test2.shape)\n",
    "\n",
    "# Create an empty list and append the clean reviews one by one\n",
    "num_reviews3 = len(test2[\"reviewText\"])\n",
    "clean_test_reviews3 = [] \n",
    "\n",
    "print (\"Cleaning and parsing the test set reviews...\\n\")\n",
    "for i in range(0,num_reviews3):\n",
    "    if( (i+1) % 1000 == 0 ):\n",
    "        print (\"Review %d of %d\\n\" % (i+1, num_reviews3))\n",
    "    clean_review3 = review_to_words( test2[\"reviewText\"][i] )\n",
    "    clean_test_reviews3.append( clean_review3 )\n",
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features3 = vectorizer2.transform(clean_test_reviews3)\n",
    "test_data_features3 = test_data_features3.toarray()\n",
    "\n",
    "# Use the random forest to label predictions\n",
    "result3 = forest2.predict(test_data_features3)\n",
    "\n",
    "# Copy the results to a pandas dataframe \n",
    "output4 = pd.DataFrame( data={\"reviewText\":test2[\"reviewText\"], \"predicted\":result3 , \"originalRating\" :test2[\"rating1\"] } )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data set with predicted polarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of the Random Forest classifier when predicting three classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print (\"Accuracy Rate for Random Forest classifier, which is calculated by accuracy_score() is: %f\" % accuracy_score(output4.originalRating, output4.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(output4.originalRating, output4.predicted,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our data using the features with Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb1 = MultinomialNB()\n",
    "nb1.fit( train_data_features2, train2[\"rating1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying our  Naive Bayes model on test set to predict the polarity of the review  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_reviews3 = len(test2[\"reviewText\"])\n",
    "clean_test_reviews3 = [] \n",
    "\n",
    "print (\"Cleaning the test set reviews...\\n\")\n",
    "for i in range(0,num_reviews3):\n",
    "    if( (i+1) % 1000 == 0 ):\n",
    "        print (\"Review %d of %d\\n\" % (i+1, num_reviews3))\n",
    "    clean_review3 = review_to_words( test2[\"reviewText\"][i] )\n",
    "    clean_test_reviews3.append( clean_review3 )\n",
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features4 = vectorizer2.transform(clean_test_reviews3)\n",
    "test_data_features4 = test_data_features4.toarray()\n",
    "\n",
    "# Use the naive bayes to make label predictions\n",
    "result5 = nb1.predict(test_data_features4)\n",
    "\n",
    "# Copy the results to a pandas dataframe \n",
    "output5 = pd.DataFrame( data={\"reviewText\":test2[\"reviewText\"], \"predicted\":result5 , \"originalRating\" :test2[\"rating1\"]} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of the Naive Bayes classifier when predicting three classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Accuracy Rate for Naive Bayes classifier, which is calculated by accuracy_score() is: %f\" % accuracy_score(output5.originalRating, output5.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(output5.originalRating, output5.predicted,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our SVM model using the features generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_data_features2, train2[\"rating1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying our SVM model on test set to predict the polarity of the review  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_reviews4 = len(test2[\"reviewText\"])\n",
    "clean_test_reviews4 = [] \n",
    "\n",
    "print (\"Cleaning the test set reviews...\\n\")\n",
    "for i in range(0,num_reviews4):\n",
    "    if( (i+1) % 1000 == 0 ):\n",
    "        print (\"Review %d of %d\\n\" % (i+1, num_reviews4))\n",
    "    clean_review4 = review_to_words( test2[\"reviewText\"][i] )\n",
    "    clean_test_reviews4.append( clean_review4 )\n",
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features5 = vectorizer2.transform(clean_test_reviews4)\n",
    "test_data_features5 = test_data_features5.toarray()\n",
    "\n",
    "# Use the SVM to make label predictions\n",
    "result6 = clf.predict(test_data_features5)\n",
    "\n",
    "# Copy the results to a pandas dataframe \n",
    "output6 = pd.DataFrame( data={\"reviewText\":test2[\"reviewText\"], \"predicted\":result6 , \"originalRating\" :test2[\"rating1\"]} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of the SVM classifier when predicting three classes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Accuracy Rate for SVM classifier, which is calculated by accuracy_score() is: %f\" % accuracy_score(output6.originalRating, output6.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(output6.originalRating, output6.predicted,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our Logistic Regression model using the features generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Training the logistic regression...\")\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e5) \n",
    "\n",
    "\n",
    "\n",
    "logreg = logreg.fit( train_data_features2, train2[\"rating1\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying our logistic regression model to predict the polarity of review in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an empty list and append the clean reviews one by one\n",
    "num_reviews = len(test2[\"reviewText\"])\n",
    "clean_test_reviews = [] \n",
    "\n",
    "print (\"Cleaning the test set reviews...\\n\")\n",
    "for i in range(0,num_reviews):\n",
    "    if( (i+1) % 1000 == 0 ):\n",
    "        print (\"Review %d of %d\\n\" % (i+1, num_reviews))\n",
    "    clean_review = review_to_words( test2[\"reviewText\"][i] )\n",
    "    clean_test_reviews.append( clean_review )\n",
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features = vectorizer2.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "# Use the random forest to make label predictions\n",
    "result7 = logreg.predict(test_data_features)\n",
    "\n",
    "# Copy the results to a pandas dataframe \n",
    "output7 = pd.DataFrame( data={\"reviewText\":test2[\"reviewText\"], \"predicted\":result7 , \"originalRating\" :test2[\"rating1\"] } )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Accuracy Rate for logistic classifier, which is calculated by accuracy_score() is: %f\" % accuracy_score(output7.originalRating, output7.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F- Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1_score(output7.originalRating, output7.predicted,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new = 'hello! this is great. Awesome. Have fun'\n",
    "clean_test_reviews9 = []\n",
    "clean_review9 = review_to_words( new )\n",
    "clean_test_reviews9.append( clean_review9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_test_reviews9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_features9 = vectorizer.transform(clean_test_reviews9)\n",
    "test_data_features9 = test_data_features9.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb.predict(test_data_features9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
